import os
import argparse
import cv2
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint


# -----------------------------
# 1) Tiá»n xá»­ lÃ½ & tiá»‡n Ã­ch
# -----------------------------
def preprocess_image(path):
    """Äá»c áº£nh xÃ¡m, cÃ¢n báº±ng histogram, sharpen nháº¹, resize 224x224, chuáº©n hÃ³a [0,1]."""
    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh: {path}")
        return None
    img = cv2.equalizeHist(img)
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]], dtype=np.float32)
    img = cv2.filter2D(img, -1, kernel)
    img = cv2.resize(img, (224, 224))
    img = img.astype(np.float32) / 255.0
    return img


def show_before_after(path):
    """Hiá»ƒn thá»‹ áº£nh gá»‘c vÃ  sau xá»­ lÃ½ (chá»‰ dÃ¹ng Ä‘á»ƒ kiá»ƒm tra nhanh local)."""
    original = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    processed = preprocess_image(path)
    if original is None or processed is None:
        print("âš ï¸ KhÃ´ng thá»ƒ hiá»ƒn thá»‹ áº£nh.")
        return
    plt.figure(figsize=(8, 4))
    plt.subplot(1, 2, 1); plt.imshow(original, cmap='gray'); plt.title('áº¢nh gá»‘c'); plt.axis('off')
    plt.subplot(1, 2, 2); plt.imshow(processed, cmap='gray'); plt.title('áº¢nh sau xá»­ lÃ½'); plt.axis('off')
    plt.tight_layout(); plt.show()


def safe_read_csv(csv_path):
    """Äá»c CSV an toÃ n, tá»± thá»­ utf-8 rá»“i latin1; chuáº©n hÃ³a tÃªn cá»™t (lower, strip)."""
    if not os.path.exists(csv_path):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y file CSV: {csv_path}")

    try:
        df = pd.read_csv(csv_path, encoding="utf-8")
    except UnicodeDecodeError:
        df = pd.read_csv(csv_path, encoding="latin1")
        print("âš ï¸ ÄÃ£ chuyá»ƒn sang encoding 'latin1' do lá»—i UTF-8.")
    df.columns = df.columns.str.strip().str.lower()
    return df


def ensure_dirs(*dirs):
    for d in dirs:
        os.makedirs(d, exist_ok=True)


# -----------------------------
# 2) Load dá»¯ liá»‡u tá»« CSV + áº£nh
# -----------------------------
def load_dataset(csv_path, image_folder, name_col='tÃªn', label_col='nhÃ£n', num_classes=5):
    df = safe_read_csv(csv_path)
    print("ğŸ“‹ CÃ¡c cá»™t:", df.columns.tolist())

    # Kiá»ƒm tra cá»™t báº¯t buá»™c
    if name_col not in df.columns:
        raise KeyError(f"âŒ KhÃ´ng cÃ³ cá»™t '{name_col}' trong CSV.")
    if label_col not in df.columns:
        raise KeyError(f"âŒ KhÃ´ng cÃ³ cá»™t '{label_col}' trong CSV.")

    X, y = [], []
    missing, unreadable = 0, 0

    for _, row in df.iterrows():
        filename = str(row[name_col]).strip()
        label = row[label_col]
        img_path = os.path.join(image_folder, filename)
        if not os.path.exists(img_path):
            missing += 1
            continue
        img = preprocess_image(img_path)
        if img is None:
            unreadable += 1
            continue
        X.append(img)
        y.append(int(label))

    if missing or unreadable:
        print(f"â„¹ï¸ áº¢nh thiáº¿u: {missing} | áº¢nh Ä‘á»c lá»—i: {unreadable}")

    if len(X) == 0:
        raise RuntimeError("âŒ KhÃ´ng náº¡p Ä‘Æ°á»£c máº«u nÃ o. Kiá»ƒm tra Ä‘Æ°á»ng dáº«n áº£nh & CSV.")

    X = np.array(X, dtype=np.float32).reshape(-1, 224, 224, 1)
    y = to_categorical(np.array(y, dtype=np.int32), num_classes=num_classes)
    return X, y


# -----------------------------
# 3) Model
# -----------------------------
def build_model(num_classes=5):
    model = Sequential([
        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 1)),
        MaxPooling2D(2, 2),
        Conv2D(64, (3, 3), activation='relu'),
        MaxPooling2D(2, 2),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    model.compile(
        optimizer=Adam(learning_rate=5e-5),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )
    return model


# -----------------------------
# 4) Váº½ biá»ƒu Ä‘á»“
# -----------------------------
def plot_training_history(history):
    plt.figure(figsize=(10, 4))
    # Accuracy
    plt.subplot(1, 2, 1)
    plt.plot(history.history['accuracy'], label='Train Accuracy')
    if 'val_accuracy' in history.history:
        plt.plot(history.history['val_accuracy'], label='Val Accuracy')
    plt.title('Accuracy over Epochs'); plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend()
    # Loss
    plt.subplot(1, 2, 2)
    plt.plot(history.history['loss'], label='Train Loss')
    if 'val_loss' in history.history:
        plt.plot(history.history['val_loss'], label='Val Loss')
    plt.title('Loss over Epochs'); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend()
    plt.tight_layout(); plt.show()


def plot_right_wrong_counts(y_true_classes, y_pred_classes, num_classes):
    correct_counts = np.zeros(num_classes)
    incorrect_counts = np.zeros(num_classes)
    for t, p in zip(y_true_classes, y_pred_classes):
        if t == p: correct_counts[t] += 1
        else:      incorrect_counts[t] += 1

    labels = [f'Lá»›p {i}' for i in range(num_classes)]
    x = np.arange(num_classes); width = 0.35
    plt.figure(figsize=(10, 5))
    plt.bar(x - width/2, correct_counts, width, label='Dá»± Ä‘oÃ¡n Ä‘Ãºng')
    plt.bar(x + width/2, incorrect_counts, width, label='Dá»± Ä‘oÃ¡n sai')
    plt.xticks(x, labels); plt.ylabel('Sá»‘ lÆ°á»£ng máº«u')
    plt.title('Sá»‘ lÆ°á»£ng dá»± Ä‘oÃ¡n Ä‘Ãºng/sai theo nhÃ£n'); plt.legend()
    plt.tight_layout(); plt.show()


def plot_confusion(y_true_classes, y_pred_classes, num_classes):
    cm = confusion_matrix(y_true_classes, y_pred_classes)
    plt.figure(figsize=(8, 6))
    plt.imshow(cm, interpolation='nearest')
    plt.title('Ma tráº­n nháº§m láº«n'); plt.colorbar()
    tick_marks = np.arange(num_classes)
    class_names = [f'NhÃ£n {i}' for i in range(num_classes)]
    plt.xticks(tick_marks, class_names, rotation=45)
    plt.yticks(tick_marks, class_names)

    # Ghi sá»‘
    thresh = cm.max() / 2.0 if cm.max() > 0 else 0.5
    for i in range(num_classes):
        for j in range(num_classes):
            plt.text(j, i, format(cm[i, j], 'd'),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")
    plt.ylabel('Thá»±c táº¿'); plt.xlabel('Dá»± Ä‘oÃ¡n'); plt.tight_layout(); plt.show()


# -----------------------------
# 5) Main
# -----------------------------
def main():
    parser = argparse.ArgumentParser(description="Train CNN phÃ¢n loáº¡i bÃ n chÃ¢n (VN).")
    parser.add_argument("--csv", default=os.getenv("CSV_PATH", "./data/VietNam.csv"),
                        help="ÄÆ°á»ng dáº«n CSV (máº·c Ä‘á»‹nh ./data/VietNam.csv)")
    parser.add_argument("--img_dir", default=os.getenv("IMG_DIR", "./images/VietNam"),
                        help="ThÆ° má»¥c áº£nh (máº·c Ä‘á»‹nh ./images/VietNam)")
    parser.add_argument("--epochs", type=int, default=int(os.getenv("EPOCHS", 60)))
    parser.add_argument("--batch", type=int, default=int(os.getenv("BATCH", 68)))
    parser.add_argument("--num_classes", type=int, default=int(os.getenv("NUM_CLASSES", 5)))
    parser.add_argument("--name_col", default=os.getenv("NAME_COL", "tÃªn"))
    parser.add_argument("--label_col", default=os.getenv("LABEL_COL", "nhÃ£n"))
    parser.add_argument("--demo_image", default=os.getenv("DEMO_IMAGE", ""))  # tuá»³ chá»n: xem trÆ°á»›c/sau
    args = parser.parse_args()

    # Táº¡o thÆ° má»¥c models/
    ensure_dirs("./models")

    # Demo xem trÆ°á»›c/sau náº¿u cung cáº¥p demo_image
    if args.demo_image and os.path.exists(args.demo_image):
        show_before_after(args.demo_image)

    # Náº¡p dá»¯ liá»‡u
    print(f"ğŸ“‚ CSV: {args.csv}")
    print(f"ğŸ–¼ï¸  IMG DIR: {args.img_dir}")
    X, y = load_dataset(args.csv, args.img_dir,
                        name_col=args.name_col, label_col=args.label_col,
                        num_classes=args.num_classes)

    # Chia dá»¯ liá»‡u
    y_int = np.argmax(y, axis=1)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42, stratify=y_int
    )

    # Model
    model = build_model(num_classes=args.num_classes)

    # Callbacks
    ckpt_path = "./models/best_model.keras"
    callbacks = [
        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
        ModelCheckpoint(ckpt_path, monitor='val_loss', save_best_only=True, verbose=1)
    ]

    # Train
    history = model.fit(
        X_train, y_train,
        validation_split=0.2,
        epochs=args.epochs,
        batch_size=args.batch,
        callbacks=callbacks,
        verbose=1
    )

    # Evaluate
    loss, acc = model.evaluate(X_test, y_test, verbose=0)
    print(f"âœ… Äá»™ chÃ­nh xÃ¡c trÃªn táº­p kiá»ƒm tra: {acc:.2%}")

    # Save final
    final_model_path = "./models/flatfoot_model_VietNam_final.keras"
    model.save(final_model_path)
    print(f"ğŸ’¾ ÄÃ£ lÆ°u mÃ´ hÃ¬nh: {final_model_path}")

    # Dá»± Ä‘oÃ¡n & thá»‘ng kÃª
    y_pred = model.predict(X_test, verbose=0)
    y_pred_classes = np.argmax(y_pred, axis=1)
    y_true_classes = np.argmax(y_test, axis=1)

    # Metrics tá»«ng lá»›p
    precision = precision_score(y_true_classes, y_pred_classes, average=None, zero_division=0)
    recall = recall_score(y_true_classes, y_pred_classes, average=None, zero_division=0)
    f1 = f1_score(y_true_classes, y_pred_classes, average=None, zero_division=0)

    print("ğŸ” Precision:", precision)
    print("ğŸ” Recall   :", recall)
    print("ğŸ” F1-score :", f1)

    # Váº½ Ä‘á»“ thá»‹
    plot_training_history(history)
    plot_right_wrong_counts(y_true_classes, y_pred_classes, args.num_classes)
    plot_confusion(y_true_classes, y_pred_classes, args.num_classes)


if __name__ == "__main__":
    # Giáº£m log TensorFlow khi deploy
    os.environ.setdefault("TF_CPP_MIN_LOG_LEVEL", "2")
    tf.get_logger().setLevel("ERROR")
    main()
