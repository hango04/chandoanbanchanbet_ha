import streamlit as st
from tensorflow.keras.models import load_model
import tensorflow as tf
import numpy as np
import cv2
import tempfile, os, zipfile

# ====== C·∫•u h√¨nh trang ======
st.set_page_config(page_title="D·ª± ƒëo√°n b√†n ch√¢n", layout="centered")

st.title("ü¶∂ D·ª± ƒëo√°n nh√£n b√†n ch√¢n t·ª´ ·∫£nh (1 ·∫£nh)")
st.caption("H·ªó tr·ª£ model: .keras, .h5, .tflite, SavedModel (.zip). ONNX (.onnx) n·∫øu c√≥ onnxruntime.")

# ====== √Ånh x·∫° nh√£n ======
LABEL_MAP = {
    0: "Binh thuong",
    1: "Bet nhe",
    2: "Bet trung b√¨nh",
    3: "Bet nang",
    4: "Khong xac dinh"
}

# ---------- Utilities ----------
def ensure_3ch(x1ch):
    # (H,W,1) -> (H,W,3)
    return np.repeat(x1ch, 3, axis=-1)

def preprocess_image_for_shape(image_bytes, target_hw=(224,224), channels=1, norm="0_1"):
    """
    ƒê·ªçc bytes -> tr·∫£ (rgb_for_show, x[1,H,W,C] float32)
    - target_hw: (H,W)
    - channels: 1 ho·∫∑c 3
    - norm: "0_1" (m·∫∑c ƒë·ªãnh) ho·∫∑c "-1_1"
    """
    file_bytes = np.frombuffer(image_bytes, np.uint8)
    bgr = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)  # BGR
    if bgr is None:
        return None, None

    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)
    gray = cv2.equalizeHist(gray)
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]], dtype=np.float32)
    gray = cv2.filter2D(gray, -1, kernel)
    h, w = target_hw
    gray = cv2.resize(gray, (w, h)).astype("float32")

    if norm == "0_1":
        gray = gray / 255.0
    elif norm == "-1_1":
        gray = (gray / 127.5) - 1.0

    if channels == 1:
        x = np.expand_dims(gray, axis=-1)  # (H,W,1)
    else:
        x = np.expand_dims(gray, axis=-1)  # (H,W,1)
        x = ensure_3ch(x)                  # (H,W,3)

    x = np.expand_dims(x, axis=0)         # (1,H,W,C)
    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB), x


# ----- Loaders cho c√°c ƒë·ªãnh d·∫°ng -----
def load_keras_or_h5(tmp_path):
    model = load_model(tmp_path)
    # Suy input shape
    ishape = model.inputs[0].shape  # (None,H,W,C)
    h = int(ishape[1]); w = int(ishape[2]); c = int(ishape[3])
    def predict_fn(x):
        # ƒë·∫£m b·∫£o dtype float32 cho Keras
        probs = model.predict(x.astype(np.float32), verbose=0)
        return probs
    return predict_fn, (h, w, c), "0_1"  # ƒëa s·ªë model c·ªßa b·∫°n d√πng [0,1]

def load_savedmodel_zip(zip_file_bytes):
    # Gi·∫£i n√©n zip ra th∆∞ m·ª•c t·∫°m r·ªìi load_model
    tmpdir = tempfile.mkdtemp()
    zf = zipfile.ZipFile(zip_file_bytes)
    zf.extractall(tmpdir)
    zf.close()
    model = tf.keras.models.load_model(tmpdir)
    ishape = model.inputs[0].shape
    h = int(ishape[1]); w = int(ishape[2]); c = int(ishape[3])
    def predict_fn(x):
        return model.predict(x.astype(np.float32), verbose=0)
    return predict_fn, (h, w, c), "0_1"

def load_tflite(tmp_path):
    interpreter = tf.lite.Interpreter(model_path=tmp_path)
    interpreter.allocate_tensors()
    in_det = interpreter.get_input_details()[0]
    out_det = interpreter.get_output_details()[0]
    ishape = in_det["shape"]  # e.g. [1,224,224,1] or [1,224,224,3]
    h = int(ishape[1]); w = int(ishape[2]); c = int(ishape[3])

    # TFLite th∆∞·ªùng d√πng float32 input. N·∫øu model c·ªßa b·∫°n ti·ªÅn x·ª≠ l√Ω [-1,1], b·∫°n ƒë·ªïi norm b√™n d∆∞·ªõi.
    def predict_fn(x):
        # Nh√©t ƒë√∫ng dtype theo TFLite
        x_in = x.astype(in_det["dtype"])
        interpreter.set_tensor(in_det["index"], x_in)
        interpreter.invoke()
        y = interpreter.get_tensor(out_det["index"])
        return y.astype(np.float32)

    # M·∫∑c ƒë·ªãnh norm "0_1". N·∫øu model c·∫ßn -1..1, ƒë·ªïi "norm_hint" th√†nh "-1_1".
    norm_hint = "0_1"
    return predict_fn, (h, w, c), norm_hint

def load_onnx(tmp_path):
    try:
        import onnxruntime as ort
    except ImportError as e:
        raise RuntimeError("Thi·∫øu onnxruntime. C√†i: pip install onnxruntime") from e

    sess = ort.InferenceSession(tmp_path, providers=["CPUExecutionProvider"])
    in_name = sess.get_inputs()[0].name
    ishape = sess.get_inputs()[0].shape  # [1,C,H,W] ho·∫∑c [1,H,W,C] tu·ª≥ model
    # Chu·∫©n: nhi·ªÅu ONNX d√πng NCHW. Ta c·ªë g·∫Øng suy lu·∫≠n:
    # n·∫øu ishape c√≥ 4 chi·ªÅu v√† ishape[1] in {1,3} => coi l√† NCHW
    is_nchw = (len(ishape) == 4 and isinstance(ishape[1], int) and ishape[1] in (1,3))
    if is_nchw:
        c = int(ishape[1]); h = int(ishape[2]); w = int(ishape[3])
    else:
        # fallback coi nh∆∞ NHWC
        h = int(ishape[1]); w = int(ishape[2]); c = int(ishape[3])

    def predict_fn(x):
        # ONNX th∆∞·ªùng mu·ªën float32; n·∫øu NCHW th√¨ transpose
        x_in = x.astype(np.float32)
        if is_nchw:
            x_in = np.transpose(x_in, (0, 3, 1, 2))  # NHWC->NCHW
        preds = sess.run(None, {in_name: x_in})[0]
        # ƒë·∫£m b·∫£o tr·∫£ probs shape (1,num_classes)
        if preds.ndim > 2:
            preds = preds.reshape((preds.shape[0], -1))
        return preds.astype(np.float32)

    norm_hint = "0_1"
    return predict_fn, (h, w, c), norm_hint


# ====== T·∫£i model t·ª± ƒë·ªông trong th∆∞ m·ª•c d·ª± √°n ======
st.subheader("1) T·∫£i model")

default_model_path = "flatfoot_model_VietNam_light.keras"
predict_fn = None
input_shape = (224, 224, 3)  # v√¨ b·∫°n hu·∫•n luy·ªán v·ªõi MobileNetV2 (RGB)
norm_hint = "0_1"

# N·∫øu file model c√≥ s·∫µn trong repo
if os.path.exists(default_model_path):
    with st.spinner("ƒêang t·∫£i model t·ª´ th∆∞ m·ª•c..."):
        try:
            model = load_model(default_model_path)
            ishape = model.inputs[0].shape
            h, w, c = int(ishape[1]), int(ishape[2]), int(ishape[3])

            def predict_fn(x):
                return model.predict(x.astype(np.float32), verbose=0)

            input_shape = (h, w, c)
            st.success(f"‚úÖ Model ƒë√£ t·∫£i: {default_model_path} (Input shape: {input_shape})")

        except Exception as e:
            st.error(f"Kh√¥ng load ƒë∆∞·ª£c model m·∫∑c ƒë·ªãnh: {e}")

else:
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y model {default_model_path}. H√£y ch·∫Øc r·∫±ng file n·∫±m c√πng th∆∞ m·ª•c app.py")


# ====== Upload ·∫£nh v√† d·ª± ƒëo√°n ======
st.subheader("2) T·∫£i ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n")
img_file = st.file_uploader("Ch·ªçn ·∫£nh", type=["jpg", "jpeg", "png", "bmp", "tif", "tiff"])

# Cho ph√©p ch·ªânh norm n·∫øu bi·∫øt m√¥ h√¨nh c·∫ßn -1..1
norm_opt = st.selectbox("Chu·∫©n ho√° ƒë·∫ßu v√†o", ["0_1 (m·∫∑c ƒë·ªãnh)", "-1_1"], index=0)
norm_to_use = "0_1" if "0_1" in norm_opt else "-1_1"

predict_btn = st.button("üöÄ D·ª± ƒëo√°n")

if predict_btn:
    if predict_fn is None:
        st.error("Vui l√≤ng t·∫£i model tr∆∞·ªõc.")
    elif img_file is None:
        st.error("Vui l√≤ng ch·ªçn m·ªôt ·∫£nh.")
    else:
        H, W, C = input_shape
        with st.spinner("ƒêang ti·ªÅn x·ª≠ l√Ω & d·ª± ƒëo√°n..."):
            rgb, x = preprocess_image_for_shape(img_file.read(), target_hw=(H, W), channels=C, norm=norm_to_use)
            if rgb is None:
                st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh. Vui l√≤ng th·ª≠ ·∫£nh kh√°c.")
            else:
                try:
                    probs = predict_fn(x)
                    cls = int(np.argmax(probs))
                    conf = float(np.max(probs))
                    desc = LABEL_MAP.get(cls, "Khong ro")

                    st.write(f"**K·∫øt qu·∫£:** Nh√£n `{cls}` ‚Äì **{desc}** v·ªõi ƒë·ªô tin c·∫≠y **{conf:.2%}**")

                    # V·∫Ω text l√™n ·∫£nh
                    text = f"Nhan {cls}: {desc} ({conf:.2%})"
                    h_img, w_img = rgb.shape[:2]
                    scale = max(0.6, min(1.2, w_img / 800))
                    cv2.putText(rgb, text, (20, int(40*scale)),
                                cv2.FONT_HERSHEY_SIMPLEX, scale, (0, 255, 0), 2, cv2.LINE_AA)

                    st.image(rgb, caption="·∫¢nh c√≥ g·∫Øn nh√£n d·ª± ƒëo√°n", use_container_width=True)
                except Exception as e:
                    st.error(f"L·ªói khi d·ª± ƒëo√°n: {e}")

st.divider()
st.caption("M·∫πo: N·∫øu TFLite/ONNX c·∫ßn chu·∫©n ho√° ƒë·∫ßu v√†o [-1,1], h√£y ƒë·ªïi m·ª•c 'Chu·∫©n ho√° ƒë·∫ßu v√†o' ·ªü tr√™n.")
